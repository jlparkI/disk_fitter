# Disk Fitter


Disk Fitter is a GUI application designed for fitting and visualizing the data generated by microbiological
assays. Disk Fitter plots and fits the data with a user-selected algorithm and a variety of user-selected criteria
to find optimal cutoffs for predicting the results of the second assay from the outcome of the first. Error rates are
automatically calculated and the analyst can export the results to Excel in an appropriate format for further use.

![screenshot1](/screenshots/screenshot1.png)

![screenshot2](/screenshots/screenshot2.png)

![screenshot3](/screenshots/screenshot3.png)

For background, installation and usage, see the User Guide below.

## User Guide

(in progress)

## Background

When a patient has an infection, doctors need to determine whether a bacterial strain can be killed by the antibiotic they would like to use or is resistant to it. They can do this in several ways:

+ By growing the strain in broth containing diluted concentrations of the antibiotic to determine the smallest concentration that stops the strain from growing (the “Minimum Inhibitory Concentration” or MIC). This is the preferred and most reliable test but is also the most inconvenient. In order to run it the hospital/lab has to have the pure antibiotic in powder form which may not be available.

+ By growing the bacteria in the presence of a disk containing the antibiotic. The antibiotic diffuses outwards from the disk. The more resistant the bacteria are, the closer they will grow to the disk, and the smaller the zone around the disk will be. The zone around the disk is measured in millimeters. This is less reliable than the MIC test but is easier for most hospitals because pharmaceutical companies provide disks that hospitals can use.

+ Occasionally antibiotics are also tested by measuring the MIC using a strip called an “E-Test”. This measurement gives an MIC like the broth dilution test but is less reliable than the broth dilution test.

Frequently, a hospital just wants to know whether they can treat a patient with an antibiotic or not. So MICs are divided into three categories based on values called “breakpoints”. These categories are “Susceptible”, “Intermediate” and “Resistant”. If the bug is susceptible, it’s ok to go ahead and treat. If the bug is intermediate, maybe this antibiotic can be used, this decision is up to the doctor, and if it’s resistant definitely do not use this antibiotic. If the breakpoints are 2 and 16, for example, a bug with an MIC less than 2 is susceptible (good to treat), and a bug with an MIC less than 16 but greater than 2 is intermediate. The problem is that these categories are set based on broth MICs, whereas the hospital may need to use a disk test or E-test instead (tests 2 and 3). 

So microbiologists must find out how the disk and (sometimes) E-test measurements correspond to the broth MICs. The goal is to pick disk breakpoints/cutoffs and E-test breakpoints/cutoffs that give results which match the results of the gold-standard MIC test as reliably as possible. So if based on the MIC test, strains A-G should be classified as “Resistant” and strains H-Z should be classified as “Susceptible”, we need to pick a disk cutoff that would classify as many of them correctly as possible. 
In other words, we can think of this as a simple supervised learning prediction task. Given a vector [1,disk zone], we need to correctly predict membership in an output category belonging to the set {0,1,2}, where 0 is susceptible, 1 is intermediate and 2 is resistant. We want to find two linear boundaries (disk zone cutoff for susceptible vs intermediate and disk zone cutoff for intermediate vs resistant) that maximize the accuracy of predictions made using the disks. Two simple approaches for choosing such boundaries are logistic regression, which tries to maximize the probability of correctly choosing output categories but is easily thrown off by outliers in smaller datasets, and a depth-1 decision tree classifier, which tries to maximize the purity of the populations on either side of the split point and is far more robust to outliers.

Disk Fitter incorporates the following features:

+ Provides a simple and intuitive GUI interface;
+ Offers the analyst the ability to import either MIC vs E-test MIC or MIC vs disk data from Excel, automatically fit and plot the data and the error rates using either logistic regression or decision tree based approaches;
+ Offers the analyst the ability to manually choose cutoffs if the analyst prefers this approach to the auto-fit procedure and see their effect on the error rate;
+ Finally, the analyst can export the heatmap plot, error rate table and other results to Excel for further review.

## Installation

Disk Fitter is available for download as a precompiled executable for 64-bit Windows (see the Releases tab above). 
Simply download, extract the zip, place in your preferred directory and double-click to run. 
This is the easy way to obtain & run Disk Fitter. Be forewarned that Disk 
Fitter may take ~20 seconds to load -- this is fairly typical.

While Disk Fitter was intended for Windows, it can also be run on Linux/Mac by starting it from the command line;
it will load much more quickly this way, although this approach requires some more 
familiarity with Python and with your system's commandline.
You must have Python 3 (preferably >3.5) installed. Next, clone the repo, 
create a new virtual environment and install the indicated libraries as shown below 
(instructions shown are for Linux / MacOS).

```
git clone  https://github.com/jlparkI/disk_fitter_1.0
cd disk_fitter_1.0
python3 -m venv env
source env/bin/activate
pip install matplotlib numpy pandas scikit-learn PyQt5
cd scripts
python main.py
```


## QuickStart

Double-click on the Disk Fitter icon to run the program (unless running from the commandline, 
in which case follow the instructions above). It may take 15-20 seconds to load, this is 
normal. You'll get the welcome prompt:

![tutorial1](/screenshots/tutorial1.jpg)

followed by the main window as shown below. Take a moment to explore / familiarize
yourself with all of the available options.

![tutorial2](/screenshots/tutorial2.jpg)

You can load data to the main window using the "Import Data" button, then you
can change the fitting and plotting options (choice of fitting algorithm, MIC breakpoints, manual
override for manual cutoff selection, strain name, color palette etc.). You 
can select new options as many times as you like. Each time you select new
options or import a new dataset, you must click "Fit/Plot Data" before the plot
and error counts tables are updated. Until you click "Fit/Plot", the update
does not take place. Once the data plots, a heatmap is shown on the left,
an error table with the error categories generally recognized by microbiologists
on the right.

![screenshot1](/screenshots/screenshot1.png)

If you try to do something illegal, the program will give you a zombie-themed
error message:

![screenshot3](/screenshots/screenshot3.png)

A message box with a picture of a microbiologist, by contrast, means you're trying to 
do something that is not illegal but is also not part of the standard workflow:

Once you've selected a fitting algorithm and/or picked manual cutoffs that give
you an acceptable result, you can save the heatmap and error plot to file using the
save button indicated in the screenshot below.

![tutorial3](/screenshots/tutorial3.png)

Alternatively, you can first add a title to the heatmap plot using the button to the 
left of the save button. You'll see the following prompt -- select the option shown
and click OK.

![tutorial4](/screenshots/tutorial4.png)

You can now enter your preferred title into the "Title" blank of the dialog box as 
shown below. (You can also change many other attributes of the plot and error table
although in most cases this won't improve the visualization, which is already generated
using optimal settings. Feel free to experiment however if you like!)

![tutorial5](/screenshots/tutorial5.png)

Immediately after you change the title the updated title appears as shown below. You can
now save the plot and associated error table to disk using the save icon.

![tutorial6](/screenshots/tutorial6.png)

Alternatively, if you'd rather have the results in Excel format, you can click on
"Export Results" to save to a csv file. This file will contain a text-based 
histogram similar to the heatmap shown in the plot and a text-based version
of the error counts table that you get in the application.

When reading the heatmap in the main window, it's important to notice that
the tick marks indicate the MIC and disk zone in the square above and to the right of the 
tick mark, respectively. So for example the box shown in the first figure below corresponds to MIC 16 
mg/L and disk zone 11, while the box in the second figure corresponds to MIC
2 and disk zone 20.

You can also compare MIC data generated using two different assays with Disk
Fitter. There are some subtleties to this that are covered in the MIC vs MIC
section below.


## Model Selection

There are three ways to choose cutoffs for your assay of interest in Disk Fitter: manually, using
logistic regression or using a depth-1 decision tree (it's sort of misleading to call this a tree,
since it is only depth 1, but we are using the same algorithm we would use to choose a split point
in a tree). Both algorithmic approaches use a one-versus-all strategy to pick a split separating
susceptible from the rest and another split to resistant from the rest.

On very small datasets or on unusual datasets (e.g. dataset with no susceptible or no resistant
strains), you may be able to choose split points that are more suitable than those chosen by an
algorithm, since you may be aware of other constraints on assay data interpretation not known to
the algorithm. On larger datasets, by contrast, one of the two algorithms you have available will
generally give good results. So which to choose?

The decision tree model will generally be much less susceptible to outliers. (More on why this 
is in a minute). If your dataset has outliers decision tree will be the more robust algorithm,
especially if the dataset is relatively small. Logistic regression, by contrast, will be more
heavily influenced by outliers, which may under some circumstances be desired behavior. If in
doubt, it's easy to try both -- just select one and fit, then select the other and fit, and
compare the results tables.

Why can the two approaches give different results? The decision tree model is trying to minimize
the entropy of the child populations resulting from the split (sort of like trying
to maximize the purity of these two populations). If an outlier datapoint is very far from the 
chosen split point, it will not affect the cost function of the model to any greater extent than
it would if it were close to the chosen split point. In logistic regression, by contrast, we are
using a maximum likelihood approach, meaning we want to maximize the probability of getting
the set of class labels we observe, and we assume that the log-odds are linear, so a datapoint
which is very far on one side of a splitpoint is therefore predicted to have a high probability
of belonging to the predicted class. (The split point is the line of 50% probability -- could
belong to either class, it's a coin toss). An outlier datapoint therefore has a high predicted
probability of belonging to the _wrong_ class, causing it to have a much greater effect on the 
cost function (cross-entropy) and on the gradient and thus potentially shifting the minimum to
a much greater extent. Under some circumstances this may be desired behavior, so the choice of
algorithm is left to the user.

## MIC vs MIC Data

